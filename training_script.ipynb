{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training (with Qwen 72b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initilization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating model (with 4 bit quant & lora fine tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model():\n",
    "    # 4 bit quant\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )\n",
    "\n",
    "    # loading model\n",
    "    model_name = \"Qwen/Qwen-72B\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    # LoRA\n",
    "    lora_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=32,\n",
    "        target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\"\n",
    "    )\n",
    "    \n",
    "    # prepare for training\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(data_path, tokenizer):\n",
    "    \n",
    "    # example data in form: \n",
    "    # training_data = {\n",
    "    #     'source_text': [...], \n",
    "    #     'target_text': [...] \n",
    "    # }\n",
    "    def process_translation_data(examples):\n",
    "        # prompt template\n",
    "        prompts = [\n",
    "            f\"将以下英文翻译成中文：\\n{src}\\n中文翻译：\" \n",
    "            for src in examples[\"source_text\"]\n",
    "        ]\n",
    "        \n",
    "        # output\n",
    "        targets = [f\"{tgt}</s>\" for tgt in examples[\"target_text\"]]\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = tokenizer(\n",
    "            prompts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        labels = tokenizer(\n",
    "            targets,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        )[\"input_ids\"]\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"],\n",
    "            \"attention_mask\": inputs[\"attention_mask\"],\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "    # load csv data (colums: source, target)\n",
    "    dataset = Dataset.from_csv(data_path)\n",
    "    processed_dataset = dataset.map(\n",
    "        process_translation_data,\n",
    "        batched=True,\n",
    "        remove_columns=dataset.column_names\n",
    "    )\n",
    "    \n",
    "    return processed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss function (BLEU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "def compute_metrics(eval_preds, tokenizer):\n",
    "    predictions, labels = eval_preds\n",
    "    # decode preds and labels\n",
    "    predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # bleu\n",
    "    bleu = evaluate.load(\"bleu\")\n",
    "    # sacrebleu\n",
    "    sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "    \n",
    "    # calculate score\n",
    "    bleu_score = bleu.compute(predictions=predictions, references=[[l] for l in labels])\n",
    "    sacrebleu_score = sacrebleu.compute(predictions=predictions, references=[[l] for l in labels])\n",
    "    \n",
    "    return {\n",
    "        \"bleu_score\": bleu_score[\"bleu\"],\n",
    "        \"sacrebleu_score\": sacrebleu_score[\"score\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checkpoint callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback, TrainingArguments, TrainerState, TrainerControl\n",
    "\n",
    "class CustomCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience=3, early_stopping_threshold=0.01):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping_threshold = early_stopping_threshold\n",
    "        self.best_bleu = 0\n",
    "        self.no_improve_count = 0\n",
    "        \n",
    "    def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
    "        current_bleu = metrics.get(\"eval_bleu_score\", 0)\n",
    "        \n",
    "        # If current model is the best\n",
    "        if current_bleu > self.best_bleu + self.early_stopping_threshold:\n",
    "            self.best_bleu = current_bleu\n",
    "            self.no_improve_count = 0\n",
    "            # save model\n",
    "            kwargs['model'].save_pretrained(f\"{args.output_dir}/best_model\")\n",
    "        else:\n",
    "            self.no_improve_count += 1\n",
    "            \n",
    "        # early stop\n",
    "        if self.no_improve_count >= self.early_stopping_patience:\n",
    "            print(f\"\\nEarly stopping triggered! No improvement for {self.early_stopping_patience} evaluations\")\n",
    "            control.should_training_stop = True\n",
    "            \n",
    "        print(f\"\\nCurrent BLEU: {current_bleu:.4f}, Best BLEU: {self.best_bleu:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # init model\n",
    "    model, tokenizer = setup_model()\n",
    "    \n",
    "    # train / valid data\n",
    "    train_dataset = prepare_dataset(\"train_data.csv\", tokenizer)\n",
    "    valid_dataset = prepare_dataset(\"eval_data.csv\", tokenizer)\n",
    "    \n",
    "    # training config\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./translation_model\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=4,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=100,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=500,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=500,\n",
    "        save_total_limit=5,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"bleu_score\",\n",
    "        greater_is_better=True,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "    )\n",
    "\n",
    "    callbacks = [CustomCallback(early_stopping_patience=3)]\n",
    "    \n",
    "    trainer = transformers.Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    \n",
    "    # start training\n",
    "    trainer.train(resume_from_checkpoint=True)\n",
    "    \n",
    "    # saving model\n",
    "    trainer.save_model(\"./final_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "restore training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_training(checkpoint_dir):\n",
    "    # load model\n",
    "    model, tokenizer = setup_model()\n",
    "    \n",
    "    # train / valid data\n",
    "    train_dataset = prepare_dataset(\"train_data.csv\", tokenizer)\n",
    "    valid_dataset = prepare_dataset(\"eval_data.csv\", tokenizer)\n",
    "\n",
    "    # load training status from checkpoint\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./translation_model\",\n",
    "        resume_from_checkpoint=checkpoint_dir,\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=4,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=100,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=500,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=500,\n",
    "        save_total_limit=5,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"bleu_score\",\n",
    "        greater_is_better=True,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "    )\n",
    "    \n",
    "    trainer = transformers.Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[CustomCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "    \n",
    "    # continue training\n",
    "    trainer.train(resume_from_checkpoint=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text, model_path):\n",
    "    # loading model\n",
    "    model, tokenizer = setup_model()\n",
    "    model.load_state_dict(torch.load(f\"{model_path}/pytorch_model.bin\"))\n",
    "    \n",
    "    # input\n",
    "    prompt = f\"将以下英文翻译成中文：\\n{text}\\n中文翻译：\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # inference\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.1\n",
    "    )\n",
    "    \n",
    "    translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return translation.split(\"中文翻译：\")[-1].strip()\n",
    "\n",
    "test_text = \"\"\"Two or six months prior to the expiration of \n",
    "the patent and exclusivity protection, as appropriate, \n",
    "submit an amendment to this application identifying changes, \n",
    "if any, in the conditions under which your product was \n",
    "tentatively approved. Any changes to the conditions outlined \n",
    "in this NDA require our review before final approval and the \n",
    "goal date for our review will be set accordingly. \n",
    "Your amendment should include updated labeling, chemistry, \n",
    "manufacturing and controls data, and a safety update. \n",
    "This amendment should include draft final printed labels and \n",
    "labeling which comply with all U.S. regulations (uniqueness of \n",
    "drug product appearance per 21 CFR 206; child-resistant \n",
    "packaging per 16 CFR 1700, etc.). \"\"\"\n",
    "\n",
    "translation = translate(test_text, \"./final_model\")\n",
    "print(f\"英文: {test_text}\")\n",
    "print(f\"中文翻译: {translation}\")\n",
    "\n",
    "reference = \"\"\"在专利和独占保护到期前两个月或六个月（视情况而定）\n",
    "提交对本申请的修订，说明您的产品暂时批准的条件（如果有）的变化。\n",
    "对本 NDA 中概述的条件的任何变化都需要我们在最终批准之前进行审查，\n",
    "我们将据此确定审查的目标日期。您的修订应包括更新的标签、化学、\n",
    "制造和控制数据以及安全更新。此修订应包括符合所有美国法规的最终\n",
    "印刷标签和标签草案（根据 21 CFR 206 规定药品外观的独特性；\n",
    "根据 16 CFR 1700 规定儿童安全包装等）。\"\"\"\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "score = bleu.compute(predictions=[translation], references=[[reference]])\n",
    "print(f\"BLEU分数: {score['bleu']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
