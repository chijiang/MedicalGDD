{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medical GDD Document Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "url = \"https://www.accessdata.fda.gov/scripts/cder/daf/index.cfm\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "name_cap_letters = soup.find('div', id='drugname').find_all('a')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 按首字母顺序获取全部药品分类详细页面url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总计获取到 27 个药品分类详细页面url\n"
     ]
    }
   ],
   "source": [
    "# 获取href\n",
    "medical_category_urls = []\n",
    "for letter in name_cap_letters:\n",
    "    href = letter['href']\n",
    "    # 拼接成url\n",
    "    url = \"https://www.accessdata.fda.gov\" + href\n",
    "    medical_category_urls.append(url)\n",
    "print(\"总计获取到\", len(medical_category_urls), \"个药品分类详细页面url\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取每个药品分类详细页面中的药品名和药品url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drug_name_and_url(category_url: str):\n",
    "    \"\"\"\n",
    "    Get the drug name and url of each drug in the category page\n",
    "\n",
    "    Args:\n",
    "        category_url: The url of the category page\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries, each containing the drug name, url, application number, dosage, and manufacturer\n",
    "    \"\"\"\n",
    "    ret = []\n",
    "    # Get the category page\n",
    "    response = requests.get(category_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # Differentiate the drug name ul (starts with drugName)\n",
    "    drug_name_uls = soup.find_all('ul', id=re.compile('^drugName\\d+$'))\n",
    "    for drug_name_ul in drug_name_uls:\n",
    "        # Individual drug type (same type of drug)\n",
    "        drug_name_lis = drug_name_ul.find_all('li')\n",
    "        for drug_name_li in drug_name_lis:  \n",
    "            drug_name_a = drug_name_li.find_all('a')\n",
    "\n",
    "            # Get url of each drug (Normally there is only one)\n",
    "            for drug_name_a in drug_name_a:\n",
    "                href = drug_name_a['href']\n",
    "                drug_url = \"https://www.accessdata.fda.gov\" + href\n",
    "                # Get the drug info\n",
    "                drug_info = drug_name_li.text.split(\"|\")\n",
    "                drug_name = drug_info[0].strip()\n",
    "                application_number = drug_info[1].strip()\n",
    "                dosage = drug_info[2].strip()\n",
    "                manufacturer = drug_info[3].strip()\n",
    "\n",
    "                ret.append({\n",
    "                    \"drug_name\": drug_name,\n",
    "                    \"application_number\": application_number,\n",
    "                    \"dosage\": dosage,\n",
    "                    \"manufacturer\": manufacturer,\n",
    "                    \"url\": drug_url,\n",
    "                })\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取药品列表并存储到csv文件\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for url in medical_category_urls:\n",
    "    data_list.extend(get_drug_name_and_url(url))\n",
    "data_table = pd.DataFrame(data_list)\n",
    "\n",
    "import os\n",
    "if not os.path.exists('./docs/fda'):\n",
    "    os.makedirs('./docs/fda')\n",
    "data_table.to_csv('./docs/fda/drug_list.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_table.groupby(\n",
    "    by=['drug_name', 'application_number']\n",
    ").count()[\"url\"] > 1).sum()  # 有重复的药品名和药品编号"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 说明书下载\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取全部下载连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_download_list(url: str):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # 定义一个列表来存储提取的信息\n",
    "    download_list = []\n",
    "\n",
    "    # 查找所有包含文件信息的表格\n",
    "    tables = soup.find_all('table', class_='table table-bordered')\n",
    "\n",
    "    for table in tables:\n",
    "        # 第一行为最新文本\n",
    "        latest_row = table.find('tbody').find_all('tr')[0]\n",
    "        cells = latest_row.find_all('td')\n",
    "        if len(cells) > 5:\n",
    "            action_date = cells[0].get_text(strip=True)\n",
    "            submission = cells[1].get_text(strip=True)\n",
    "            category = cells[2].get_text(strip=True)\n",
    "            links = cells[-3].find_all('a')\n",
    "            urls = [link['href'] for link in links if 'href' in link.attrs]\n",
    "\n",
    "            if urls:\n",
    "                download_list.append({\n",
    "                    'Action Date': action_date,\n",
    "                    'Submission': submission,\n",
    "                    'Category': category,\n",
    "                    'Latest URL': urls\n",
    "                })\n",
    "    \n",
    "    return download_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 下载文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(file_url: str, saving_path: str):\n",
    "    try:\n",
    "        response = requests.get(file_url, stream=True)\n",
    "        response.raise_for_status() \n",
    "        \n",
    "        os.makedirs(os.path.dirname(saving_path), exist_ok=True)\n",
    "        \n",
    "        with open(saving_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    file.write(chunk)\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"下载文件时发生错误: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO \n",
    "# - list and download label files from CDE\n",
    "# - find and parse source for clinical trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function test -- FDA downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Action Date': '10/23/2014',\n",
       "  'Submission': 'ORIG-1',\n",
       "  'Category': 'Tentative Approval',\n",
       "  'Latest URL': ['https://www.accessdata.fda.gov/drugsatfda_docs/appletter/2014/204915Orig1s000TAltr.pdf']}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_table = pd.read_csv('./docs/fda/drug_list.csv')\n",
    "\n",
    "\n",
    "idx = 32\n",
    "\n",
    "\n",
    "page_url = data_table.loc[idx, 'url']\n",
    "drug_name = re.sub(r'[^a-zA-Z0-9]', '_', data_table.loc[idx, 'drug_name']).strip(\"_\")\n",
    "manufacturer = re.sub(r'[^a-zA-Z0-9]', '_', data_table.loc[idx, 'manufacturer']).strip(\"_\")\n",
    "download_list = get_download_list(page_url)\n",
    "download_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_urls = download_list[0].get(\"Latest URL\")\n",
    "for idx, download_url in enumerate(download_urls):\n",
    "    file_name = download_list[0].get(\"Submission\") + '_' + download_list[0].get(\"Category\") + f'_{idx}.pdf'\n",
    "    download_file(\n",
    "        download_url, \n",
    "        f\"docs/fda/{manufacturer}/{drug_name}/{file_name}\"\n",
    "    )\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
