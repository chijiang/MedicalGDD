{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medical GDD Document Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "url = \"https://www.accessdata.fda.gov/scripts/cder/daf/index.cfm\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "name_cap_letters = soup.find('div', id='drugname').find_all('a')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 按首字母顺序获取全部药品分类详细页面url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总计获取到 27 个药品分类详细页面url\n"
     ]
    }
   ],
   "source": [
    "# 获取href\n",
    "medical_category_urls = []\n",
    "for letter in name_cap_letters:\n",
    "    href = letter['href']\n",
    "    # 拼接成url\n",
    "    url = \"https://www.accessdata.fda.gov\" + href\n",
    "    medical_category_urls.append(url)\n",
    "print(\"总计获取到\", len(medical_category_urls), \"个药品分类详细页面url\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取每个药品分类详细页面中的药品名和药品url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drug_name_and_url(category_url):\n",
    "    \"\"\"\n",
    "    Get the drug name and url of each drug in the category page\n",
    "\n",
    "    Args:\n",
    "        category_url: The url of the category page\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries, each containing the drug name, url, application number, dosage, and manufacturer\n",
    "    \"\"\"\n",
    "    ret = []\n",
    "    # Get the category page\n",
    "    response = requests.get(category_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # Differentiate the drug name ul (starts with drugName)\n",
    "    drug_name_uls = soup.find_all('ul', id=re.compile('^drugName\\d+$'))\n",
    "    for drug_name_ul in drug_name_uls:\n",
    "        # Individual drug type (same type of drug)\n",
    "        drug_name_lis = drug_name_ul.find_all('li')\n",
    "        for drug_name_li in drug_name_lis:  \n",
    "            drug_name_a = drug_name_li.find_all('a')\n",
    "\n",
    "            # Get url of each drug (Normally there is only one)\n",
    "            for drug_name_a in drug_name_a:\n",
    "                href = drug_name_a['href']\n",
    "                drug_url = \"https://www.accessdata.fda.gov\" + href\n",
    "                # Get the drug info\n",
    "                drug_info = drug_name_li.text.split(\"|\")\n",
    "                drug_name = drug_info[0].strip()\n",
    "                application_number = drug_info[1].strip()\n",
    "                dosage = drug_info[2].strip()\n",
    "                manufacturer = drug_info[3].strip()\n",
    "\n",
    "                ret.append({\n",
    "                    \"drug_name\": drug_name,\n",
    "                    \"application_number\": application_number,\n",
    "                    \"dosage\": dosage,\n",
    "                    \"manufacturer\": manufacturer,\n",
    "                    \"url\": drug_url,\n",
    "                })\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取药品列表并存储到csv文件\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for url in medical_category_urls:\n",
    "    data_list.extend(get_drug_name_and_url(url))\n",
    "data_table = pd.DataFrame(data_list)\n",
    "\n",
    "import os\n",
    "if not os.path.exists('./docs/fda'):\n",
    "    os.makedirs('./docs/fda')\n",
    "data_table.to_csv('./docs/fda/drug_list.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_table.groupby(\n",
    "    by=['drug_name', 'application_number']\n",
    ").count()[\"url\"] > 1).sum()  # 有重复的药品名和药品编号"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 说明书下载\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.accessdata.fda.gov/scripts/cder/daf/index.cfm?event=overview.process&ApplNo=206843'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Drug Name           Active Ingredients      Strength Dosage Form/Route  \\\n",
      "0  DAKLINZA  DACLATASVIR DIHYDROCHLORIDE  EQ 30MG BASE       TABLET;ORAL   \n",
      "1  DAKLINZA  DACLATASVIR DIHYDROCHLORIDE  EQ 60MG BASE       TABLET;ORAL   \n",
      "2  DAKLINZA  DACLATASVIR DIHYDROCHLORIDE  EQ 90MG BASE       TABLET;ORAL   \n",
      "\n",
      "  Marketing Status  TE Code  RLD  RS  \n",
      "0     Discontinued      NaN  Yes  No  \n",
      "1     Discontinued      NaN  Yes  No  \n",
      "2     Discontinued      NaN  Yes  No  \n",
      "  Action Date Submission Action Type      Submission Classification  \\\n",
      "0  07/24/2015     ORIG-1    Approval  Type 1 - New Molecular Entity   \n",
      "\n",
      "  Review Priority; Orphan Status  \\\n",
      "0                       PRIORITY   \n",
      "\n",
      "  Letters, Reviews, Labels, Patient Package Insert  Notes  \\\n",
      "0                Label (PDF)  Letter (PDF)  Review    NaN   \n",
      "\n",
      "                                                 Url  \n",
      "0  https://www.accessdata.fda.gov/drugsatfda_docs...  \n",
      "  Action Date Submission             Supplement Categories or Approval Type  \\\n",
      "0  10/16/2019    SUPPL-8                            Labeling-Package Insert   \n",
      "1  11/09/2017    SUPPL-7                            Labeling-Package Insert   \n",
      "2  02/14/2017    SUPPL-6  Labeling-Package Insert, Labeling-Patient Pack...   \n",
      "3  12/21/2016    SUPPL-5                                Manufacturing (CMC)   \n",
      "4  04/13/2016    SUPPL-4                                Manufacturing (CMC)   \n",
      "5  02/05/2016    SUPPL-3                            Efficacy-New Indication   \n",
      "6  02/05/2016    SUPPL-2                            Efficacy-New Indication   \n",
      "7  02/05/2016    SUPPL-1                            Efficacy-New Indication   \n",
      "\n",
      "    Letters, Reviews, Labels, Patient Package Insert  \\\n",
      "0                          Label (PDF)  Letter (PDF)   \n",
      "1                          Label (PDF)  Letter (PDF)   \n",
      "2                          Label (PDF)  Letter (PDF)   \n",
      "3                                                NaN   \n",
      "4                                        Label (PDF)   \n",
      "5  Label (PDF)  Letter (PDF)  Review  Summary Rev...   \n",
      "6                          Label (PDF)  Letter (PDF)   \n",
      "7  Label (PDF)  Letter (PDF)  Review  Summary Rev...   \n",
      "\n",
      "                                   Note  \\\n",
      "0                                   NaN   \n",
      "1                                   NaN   \n",
      "2                                   NaN   \n",
      "3  Label is not available on this site.   \n",
      "4                                   NaN   \n",
      "5                                   NaN   \n",
      "6                                   NaN   \n",
      "7                                   NaN   \n",
      "\n",
      "                                                 Url  \n",
      "0  https://www.accessdata.fda.gov/drugsatfda_docs...  \n",
      "1  https://www.accessdata.fda.gov/drugsatfda_docs...  \n",
      "2  https://www.accessdata.fda.gov/drugsatfda_docs...  \n",
      "3                                                NaN  \n",
      "4  https://www.accessdata.fda.gov/drugsatfda_docs...  \n",
      "5  https://www.accessdata.fda.gov/drugsatfda_docs...  \n",
      "6  https://www.accessdata.fda.gov/drugsatfda_docs...  \n",
      "7  https://www.accessdata.fda.gov/drugsatfda_docs...  \n",
      "  Action Date Submission Supplement Categories or Approval Type  \\\n",
      "0  10/16/2019    SUPPL-8                Labeling-Package Insert   \n",
      "1  11/09/2017    SUPPL-7                Labeling-Package Insert   \n",
      "2  02/14/2017    SUPPL-6                Labeling-Package Insert   \n",
      "3  02/14/2017    SUPPL-6        Labeling-Patient Package Insert   \n",
      "4  04/13/2016    SUPPL-4                    Manufacturing (CMC)   \n",
      "5  02/05/2016    SUPPL-3                Efficacy-New Indication   \n",
      "6  02/05/2016    SUPPL-2                Efficacy-New Indication   \n",
      "7  02/05/2016    SUPPL-1                Efficacy-New Indication   \n",
      "8  07/24/2015     ORIG-1                               Approval   \n",
      "\n",
      "  Letters, Reviews, Labels,  Patient Package Insert  \\\n",
      "0                                       Label (PDF)   \n",
      "1                                       Label (PDF)   \n",
      "2                                       Label (PDF)   \n",
      "3                                       Label (PDF)   \n",
      "4                                       Label (PDF)   \n",
      "5                                       Label (PDF)   \n",
      "6                                       Label (PDF)   \n",
      "7                                       Label (PDF)   \n",
      "8                                       Label (PDF)   \n",
      "\n",
      "                                                Note  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4  This supplement type does not usually require ...   \n",
      "5                                                NaN   \n",
      "6                                                NaN   \n",
      "7                                                NaN   \n",
      "8                                                NaN   \n",
      "\n",
      "                                                 Url  \n",
      "0  https://www.accessdata.fda.gov/drugsatfda_docs...  \n",
      "1  https://www.accessdata.fda.gov/drugsatfda_docs...  \n",
      "2  https://www.accessdata.fda.gov/drugsatfda_docs...  \n",
      "3  https://www.accessdata.fda.gov/drugsatfda_docs...  \n",
      "4  https://www.accessdata.fda.gov/drugsatfda_docs...  \n",
      "5  https://www.accessdata.fda.gov/drugsatfda_docs...  \n",
      "6  https://www.accessdata.fda.gov/drugsatfda_docs...  \n",
      "7  https://www.accessdata.fda.gov/drugsatfda_docs...  \n",
      "8  https://www.accessdata.fda.gov/drugsatfda_docs...  \n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "# 找到全部table\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "for table in tables:\n",
    "    # 把table转换为pandas的DataFrame\n",
    "    df = pd.read_html(StringIO(table.prettify()))\n",
    "    print(df[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Action Date', 'Submission', 'Supplement Categories or Approval Type',\n",
       "       'Letters, Reviews, Labels,  Patient Package Insert', 'Note', 'Url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_html(StringIO(table.prettify()))\n",
    "df[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Action Date Submission                 Category  \\\n",
      "0  07/24/2015     ORIG-1                 Approval   \n",
      "1  10/16/2019    SUPPL-8  Labeling-Package Insert   \n",
      "2  10/16/2019    SUPPL-8  Labeling-Package Insert   \n",
      "\n",
      "                                          Latest URL  \n",
      "0  [https://www.accessdata.fda.gov/drugsatfda_doc...  \n",
      "1  [https://www.accessdata.fda.gov/drugsatfda_doc...  \n",
      "2  [https://www.accessdata.fda.gov/drugsatfda_doc...  \n"
     ]
    }
   ],
   "source": [
    "# 定义一个列表来存储提取的信息\n",
    "data = []\n",
    "\n",
    "# 查找所有包含文件信息的表格\n",
    "tables = soup.find_all('table', class_='table table-bordered')\n",
    "\n",
    "for table in tables:\n",
    "    # 第一行为最新文本\n",
    "    latest_row = table.find('tbody').find_all('tr')[0]\n",
    "    cells = latest_row.find_all('td')\n",
    "    if len(cells) > 5:\n",
    "        action_date = cells[0].get_text(strip=True)\n",
    "        submission = cells[1].get_text(strip=True)\n",
    "        category = cells[2].get_text(strip=True)\n",
    "        links = cells[-3].find_all('a')\n",
    "        urls = [link['href'] for link in links if 'href' in link.attrs]\n",
    "\n",
    "        if urls:\n",
    "            data.append({\n",
    "                'Action Date': action_date,\n",
    "                'Submission': submission,\n",
    "                'Category': category,\n",
    "                'Latest URL': urls\n",
    "            })\n",
    "\n",
    "# 将数据转换为DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 打印或保存为CSV\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_fda_articles\u001b[39m():\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
     ]
    }
   ],
   "source": [
    "download_links\n",
    "\n",
    "def fetch_fda_articles():\n",
    "    url = \"https://www.accessdata.fda.gov/scripts/cder/daf/index.cfm\"  # 示例URL，请根据实际情况调整\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    articles = []\n",
    "    for item in soup.find_all('div', class_='views-row'):\n",
    "        title = item.find('h2').get_text(strip=True)\n",
    "        link = item.find('a')['href']\n",
    "        date = item.find('span', class_='date-display-single').get_text(strip=True)\n",
    "        articles.append({'title': title, 'link': link, 'date': date})\n",
    "    \n",
    "    return articles\n",
    "\n",
    "def fetch_nmpa_articles():\n",
    "    url = \"https://www.nmpa.gov.cn/xxgk/\"  # 示例URL，请根据实际情况调整\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    articles = []\n",
    "    for item in soup.find_all('li'):\n",
    "        title_tag = item.find('a')\n",
    "        if title_tag:\n",
    "            title = title_tag.get_text(strip=True)\n",
    "            link = title_tag['href']\n",
    "            date = item.find('span').get_text(strip=True) if item.find('span') else ''\n",
    "            articles.append({'title': title, 'link': link, 'date': date})\n",
    "    \n",
    "    return articles\n",
    "\n",
    "def save_to_csv(fda_articles, nmpa_articles):\n",
    "    fda_df = pd.DataFrame(fda_articles)\n",
    "    nmpa_df = pd.DataFrame(nmpa_articles)\n",
    "    \n",
    "    fda_df.to_csv('./docs/fda/fda_articles.csv', index=False, encoding='utf-8')\n",
    "    nmpa_df.to_csv('./docs/nmpa/nmpa_articles.csv', index=False, encoding='utf-8')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fda_articles = fetch_fda_articles()\n",
    "nmpa_articles = fetch_nmpa_articles()\n",
    "save_to_csv(fda_articles, nmpa_articles)\n",
    "print(\"文章已成功抓取并保存。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
